\documentclass{article}



\usepackage[final, nonatbib]{neurips_2024}


\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors



%% Other packages i'd like:
\usepackage{amsmath,amssymb,amsthm}
\usepackage[capitalize,noabbrev]{cleveref}



% User-defined environments...
\newtheorem{definition}{Definition}
\newtheorem{lemma}{Lemma}
\newtheorem{remark}{Remark}
\newtheorem{theorem}{Theorem}




% My LaTeX shortcuts:

\renewcommand{\aa}{\mathbb{A}}
\newcommand{\ee}{\mathbb{E}}
\newcommand{\nn}{\mathbb{N}}
\newcommand{\pp}{\mathbb{P}}
\newcommand{\rr}{\mathbb{R}}


\renewcommand{\AA}{\mathcal{A}}
\newcommand{\BB}{\mathcal{B}}

\newcommand{\FF}{\mathcal{F}}

\newcommand{\LL}{\mathcal{L}}
\newcommand{\MM}{\mathcal{M}}
\newcommand{\NN}{\mathcal{N}}
\newcommand{\OO}{\mathcal{O}}
\newcommand{\PP}{\mathcal{P}}

\renewcommand{\SS}{\mathcal{S}}
\newcommand{\TT}{\mathcal{T}}

\newcommand{\XX}{\mathcal{X}}
\newcommand{\YY}{\mathcal{Y}}


\newcommand{\Acc}{{\rm Access}}
\newcommand{\argmax}{{\rm argmax}}
\newcommand{\BR}{{\rm BR}}
\newcommand{\Flip}{{\rm Flip}}
\newcommand{\idagger}{i^{\dagger}}
\newcommand{\indicator}{\textbf{1}}
\newcommand{\Keep}{{\rm Keep}}
\newcommand{\NoB}{{\rm NoBetter}}  % a bit too long for two column...
\newcommand{\NoBetter}{{\rm NoBetter}}  % a bit too long for two column...
\newcommand{\regret}{{\rm Regret}}
\newcommand{\Sat}{{\rm Sat}}
\newcommand{\simplex}{\Delta}
\newcommand{\Uniform}{{\rm Uniform}}
\newcommand{\UnSat}{{\rm UnSat}}
\newcommand{\Worse}{{\rm Worse}}

\usepackage{bm} % for bold characters
\newcommand{\bpi}{\bm{\pi}}
\newcommand{\bvarpi}{\bm{\varpi}}
\newcommand{\bPi}{\bm{\Pi}}
\newcommand{\btheta}{\bm{\theta}}

\newcommand{\ba}{{\mathbf{a}}}
\newcommand{\br}{{\mathbf{r}}}
\newcommand{\bw}{{\mathbf{w}}}
\newcommand{\bx}{{\mathbf{x}}}
\newcommand{\by}{{\mathbf{y}}}
\newcommand{\bz}{{\mathbf{z}}}

\newcommand{\bA}{{\mathbf{A}}}
\newcommand{\bG}{{\mathbf{G}}}
\newcommand{\bX}{{\mathbf{X}}}


\newcommand{\blue}[1]{{\color{blue}#1}}
\newcommand{\gray}[1]{{\color{gray}#1}}
\newcommand{\red}[1]{{\color{red}#1}}
\newcommand{\brown}[1]{{\color{brown}#1}}


% package imported by BY for enumerating

\usepackage{enumitem}











\title{Paths to Equilibrium in Games}





%%%%%%%%%%%%%%%%% Default version (ugly)
% \author{%
%   Bora Yongacoglu \\
%   University of Toronto\\
%   \texttt{bora.yongacoglu@utoronto.ca}
%     \And
%   G\"urdal Arslan \\
%   University of Hawaii at Manoa \\ 
%   \texttt{gurdal@hawaii.edu}\\
%   \AND     
%   Lacra Pavel \\
%   University of Toronto\\
%   \texttt{pavel@control.toronto.edu} \\
%   \And
%   Serdar Y\"uksel \\
%   Queen's University \\
%   \texttt{yuksel@queensu.ca} \\
% }

%%%%%%%%%%%%%%% Trying to fix it:
\author{ 
\begin{tabular}[t]{c c c}
  Bora Yongacoglu & & G\"{u}rdal Arslan  \\
  \textnormal{University of Toronto} & & \textnormal{University of Hawaii at Manoa}  \\
  \texttt{bora.yongacoglu@utoronto.ca} & & \texttt{gurdal@hawaii.edu} \\
  \\
  Lacra Pavel &  & Serdar Y\"{u}ksel \\
  \textnormal{University of Toronto} & & \textnormal{Queen's University}  \\
  \texttt{pavel@control.toronto.edu} & &\texttt{yuksel@queensu.ca} \\
\end{tabular}
}




\begin{document}


\maketitle


\begin{abstract}
  In multi-agent reinforcement learning (MARL) and game theory, agents repeatedly interact  and revise their strategies as new data arrives, producing a sequence of strategy profiles. This paper studies sequences of strategies satisfying a pairwise constraint inspired by policy updating in reinforcement learning, where an agent who is best responding in one period does not switch its strategy in the next period. This constraint merely requires that optimizing agents do not switch strategies, but does not constrain the non-optimizing agents in any way, and thus allows for exploration. Sequences with this property are called satisficing paths, and arise naturally in many MARL algorithms.  A fundamental question about strategic dynamics is such: for a given game and initial strategy profile, is it always possible to construct a satisficing path that terminates at an equilibrium? The resolution of this question has implications about the capabilities or limitations of a class of MARL algorithms. We answer this question in the affirmative for normal-form games. Our analysis reveals a counterintuitive insight that reward deteriorating strategic updates are key to driving play to equilibrium along a satisficing path. 
\end{abstract}



% Introduction 
\input{intro_2024-10-01}
\input{related_work_2024-10-01}


%%  Section 2: model
\input{model_2024-10-01}


%%  Section 3: main theorem on normal-form games and proof
\input{main_result_2024-10-01}


% %% Section 4: discussion
\input{discussion_2024-10-01}


%%  Section 5: conclusion
\input{conclusion_2024-10-01}


%%%% Appendix after bibliography. 



%\bibliographystyle{apalike} % my preferred style: name+year, looks pretty.
\bibliographystyle{acm}  % ugly: sorts refs alphabetically, so they display in an ugly order in text... but it is shorter!


\bibliography{satisficing}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\appendix
\crefalias{section}{appendix} % uncomment if you are using cleveref
\input{appendix}



%
%       Removing NeurIPS Checklist for the arXiv version 
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




\end{document}