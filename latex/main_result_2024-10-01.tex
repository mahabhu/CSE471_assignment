\section{Existence of paths in normal-form games}  \label{sec:result}

\begin{theorem} \label{theorem:main}
    Any finite normal-form game $\Gamma$ has the satisficing paths property.
\end{theorem}


\noindent \textbf{Proof sketch.} Before presenting the formal proof, we describe the intuition of its main argument. In the proof of Theorem~\ref{theorem:main}, we construct a satisficing path from an arbitrary initial strategy $\bx_1$ to a Nash equilibrium by repeatedly switching the strategies of unsatisfied players in a way that grows the set of \emph{unsatisfied} players after the update. Once the set of unsatisfied players is maximal, we argue that a Nash equilibrium can be reached in one step by switching the strategies of the unsatisfied players. The final point represents the main technical challenge in the proof, as switching the strategies of unsatisfied players changes the objective functions for the previously satisfied players. We address this challenge by showing the existence of a Nash equilibrium on the boundary of a strategy subset in which previously satisfied players remain satisfied.

\noindent To give the complete proof, we will require some additional notation, detailed below, and some supporting results, detailed in \Cref{appendix:F-functions} and \Cref{appendix:lemma}.


\noindent \textbf{Additional notation.}  We require notation for the following  sets, defined for any $\bx \in \bX$:
\begin{align*}
    \Sat(\bx)      := \left\{ i \in [n] : x^i \in \BR^i_0 ( \bx^{-i} )      \right\},  \quad \text{and} \quad     \UnSat(\bx)    := [n] \setminus \Sat(\bx).                                                           
\end{align*}

A player in $\Sat(\bx) \subseteq [n]$ is called \emph{satisfied} (at $\bx$), and a player in $\UnSat(\bx)$ is called \emph{unsatisfied} (at $\bx$). For $\bx \in \bX$, we also define
\[
 \Acc ( \bx)    := \left\{ \by \in \bX : y^i = x^i,  \: \forall i \in \Sat(\bx)  \right\} .
\]
$\Acc( \bx )$ is the subset of strategies that are accessible from strategy $\bx$, to mean one can obtain strategy $\by \in \Acc(\bx) \subseteq \bX $ from $\bx$ by switching (at most) the strategies of players who were unsatisfied at $\bx$. We define a subset $\NoB(\bx) \subseteq \Acc(\bx)$ as 
\begin{align*}
\NoB (\bx)  :=&  \left\{ \by \in \Acc(\bx) : \UnSat(\bx) \subseteq \UnSat(\by) \right\} \\[2.5pt]
            =&   \left\{ \by \in \Acc(\bx) \middle|  \forall i \in \UnSat(\bx), \: i \in \UnSat(\by)   \right\},
\end{align*}

The set $\NoB(\bx)$ consists of strategies $\by$ that are accessible from $\bx$ and also fail to improve the status of players who were previously unsatisfied. The set name $\NoB(\bx)$ is chosen to suggest that the players unsatisfied at $\bx$ are not better off at $\by \in \NoB(\bx)$, since they are unsatisfied at both $\bx$ and $\by$. We observe $\bx \in \NoB(\bx)$, hence $\NoB(\bx)$ is non-empty. 

Finally, we define a set $\Worse(\bx) \subseteq \NoB(\bx)$ as
\begin{align*}
\Worse(\bx) :=& \left\{ \by \in \NoB(\bx) : \UnSat(\bx) \subsetneq \UnSat(\by) \right\}  \\[2.5pt]
            =&  \left\{ \by \in \NoB(\bx) \middle| \exists i \in \Sat(\bx) : i \in \UnSat(\by) \right\} \hspace{-1.5pt}.            
\end{align*}

The set $\Worse(\bx)$ consists of strategies that are accessible from $\bx$, that leave all previously unsatisfied players unsatisfied, and flip at least one previously satisfied player to being unsatisfied. In particular, if $\by \in \Worse(\bx)$, this means $| \UnSat( \by) | \geq  | \UnSat(\bx) | + 1$. We observe that $\Worse(\bx)$ may be empty, and  $\Worse(\bx) \subseteq \NoB(\bx) \subseteq \Acc(\bx) $. 




\subsection{Proof of Theorem~\ref{theorem:main}}

\begin{remark}  \label{remark:not-a-learning-algorithm}
    In the proof below, we analytically construct a path from $\bx_1$ to a Nash equilibrium. The process of selecting strategies $\bx_1, \bx_2, \cdots$ and switching the component strategy of each player is done centrally, by the analyst, and should not be interpreted as a learning algorithm.  
\end{remark}

\begin{proof}
Let $\bx_1 \in \bX$ be any initial strategy profile. We must produce a satisficing path of finite length terminating at a Nash equilibrium. Equivalently, we must produce a sequence $\bx_1, \dots, \bx_T$ with $\bx_{t+1} \in \Acc (\bx_t )$ for each $t$ and $\bx_T$ a Nash equilibrium, where the length $T$ may depend on $\bx_1$. In the trivial case that $\bx_1$ is a Nash equilibrium, we put $T=1$. The remainder of this proof focuses on the non-trivial case, where $\bx_1$ is not a Nash equilibrium. 

To begin, we produce a satisficing path $\bx_1, \dots, \bx_k$ as follows. We put $t = 1$, and while both $\Sat(\bx_t) \not= \varnothing$ and $\Worse(\bx_t) \not= \varnothing$, we arbitrarily fix $\bx_{t+1} \in \Worse(\bx_t)$ and increment $t \gets t+1$. By construction, we have 
\[
\varnothing \not= \UnSat(\bx_1) \subsetneq \cdots \subsetneq \UnSat(\bx_t) \subsetneq \UnSat(\bx_{t+1})
\]
for each non-terminal iteration $t$, where the inequality holds because $\bx_1$ is not a Nash equilibrium. Thus, the number of unsatisfied players is strictly increasing along this satisficing path. Since the number of unsatisfied players is bounded above by $n$, and since we have assumed $| \UnSat(\bx_1) | \geq 1$, this process terminates in at most $n-1$ steps. Letting $k$ denote the terminal index of this process, we have $k \leq n-1$. 


By the construction of the path $(\bx_1, \dots, \bx_k)$, (at least) one of the following holds at index $k$: either $\Sat(\bx_k) = \varnothing$ or $\Worse(\bx_k) = \varnothing$. In other words, either no player is satisfied at $\bx_k$, or there is no accessible strategy that grows the subset of unsatisfied players. %Building on this, we proceed in cases. 

\noindent \textbf{Case 1:} $\Sat(\bx_k) = \varnothing$, and all players are unsatisfied at $\bx_k$. In this case, we may switch the strategy of each player $i \in [n]$ to any successor strategy. That is, $\Acc(\bx_k) = \bX$. We fix an arbitrary Nash equilibrium $\bz_{\star}$, put $\bx_{k+1} = \bz_{\star}$, and let $T = k+1$. Then, $(\bx_1, \dots, \bx_{T})$ is a satisficing path terminating at equilibrium.

\noindent \textbf{Case 2:} $\Sat(\bx_k)\not= \varnothing$ and $\Worse(\bx_k) = \varnothing$. In this case, there are no accessible strategies that strictly grow the set of unsatisfied players. %, which is also non-empty.  %% i.e. $\UnSat ( \bx_k )$ is non-empty.  

Since $\Worse(\bx_k) = \varnothing $, the following holds: for any strategy $\by \in \NoB(\bx_k)$ and any satisfied player $i \in \Sat (\bx_k)$, we have that $i \in \Sat(\by)$. (Otherwise, if $i \in \UnSat(\by)$, then $\by \in \Worse(\bx_k) $, since it flipped a satisfied player. But this contradicts the emptiness of $\Worse(\bx_k)$.)


We now argue that there exists a strategy profile $\bx_{\star}$ accessible from $\bx_k$ such that all players unsatisfied at $\bx_k$ are satisfied at $\bx_{\star}$. That is, there exists an accessible strategy $\bx_{\star} \in \Acc ( \bx_k )$ such that 
\begin{equation} 
\UnSat(\bx_k) \subset \Sat(\bx_{\star}).  \label{subset:unsat-inside-sat}
\end{equation}

To see that such a strategy $\bx_{\star}$ exists, note that fixing the strategies of the $m$ players satisfied at $\bx_k$ defines a new game, say $\tilde{\Gamma}$, with $n-m$ players, and the new game $\tilde{\Gamma}$ admits a Nash equilibrium $\tilde{\bx}_{\star} = ( \tilde{x}^i_{\star} )_{i \in \UnSat(\bx_k )}$. We extend $\tilde{\bx}_{\star}$ to be a strategy profile in the larger game $\Gamma$ by putting $x^i_{\star} = x^i_k$ for players $i \in \Sat(\bx_k)$ while putting $x^j_{\star} = \tilde{x}^j_{\star}$ for players $j \in \UnSat(\bx_k)$. By construction, we have that $x^{j}_{\star} \in \BR^j_0 ( \bx^{-j}_{\star})$ for each $j \in \UnSat(\bx_k)$, so \eqref{subset:unsat-inside-sat} holds.

From \eqref{subset:unsat-inside-sat}, it is clear that $\bx_{\star} \notin \NoB(\bx_k)$, since $\NoB(\bx_k)$ consists of strategies accessible from $\bx_k$ in which unsatisfied agents remain unsatisfied, while the previously unsatisfied agents are satisfied at $\bx_{\star}$. 
We now state a key technical lemma, which asserts that although $\bx_{\star}$ does not belong to $\NoB(\bx_k)$, it is a limit point of this set. A proof of Lemma~\ref{lemma:equilibrium-on-boundary} given in \Cref{appendix:lemma}.

\begin{lemma} \label{lemma:equilibrium-on-boundary}
    If $\Worse( \bx_k ) = \varnothing$, then there exists a sequence $\{ \by \}_{t = 1}^{\infty}$, with $\by_t \in \NoB(\bx_k)$ for each $t$, such that $     \lim_{t \to \infty} \by_t = \bx_{\star}. $  
\end{lemma}

We will argue that $\bx_{\star}$ is a Nash equilibrium for the original game $\Gamma$. For each player $i \in [n]$, we introduce a function $F^i : \bX \to \rr$ given by $F^i ( x^i, \bx^{-i} ) = \max_{a^i \in \aa^i} R^i ( \delta_{a^i} , \bx^{-i} ) - R^i ( x^i, \bx^{-i} ),$ for each $\bx = (x^i, \bx^{-i}) \in \bX$. The functions $\{ F^i\}_{i=1}^n$ have the following useful properties, which are well known \cite{maschler2020game}, and are summarized in \Cref{appendix:F-functions}. For each player $i \in [n]$: (a)~$F^i$ is continuous on $\bX$; (b)~$F^i (\bx) \geq 0$ for all $\bx \in \bX$; (c)~for any $\bx^{-i} \in \bX^{-i}$, a strategy $x^i$ is a best response to $\bx^{-i}$ if and only if $F^i (x^i, \bx^{-i}) = 0$.

Let $(\by_t )_{t = 1}^{\infty}$ be a sequence in $\NoB(\bx_k)$ converging to $\bx_{\star}$, which exists by Lemma~\ref{lemma:equilibrium-on-boundary}. For any previously satisfied player $i \in \Sat(\bx_k)$, since $\Worse(\bx_k) = \varnothing$ and $\by_t \in \NoB(\bx_k)$, from a previous observation, we have that $i \in \Sat(\by_t)$. Equivalently, $x^i_k \in \BR^i_0 ( \by^{-i}_t )$. Re-writing this using the function $F^i$ and the notation $y^i_t = x^i_k$ for satisfied players $i \in \Sat(\bx_k)$, we have $F^i ( y^i_t , \by^{-i}_t ) = 0 $ for all $t \in \nn $ and for any $i \in \Sat(\bx_k)$. By continuity of $F^i$, we have
\[
0 = \lim_{t \to \infty} F^i ( \by_t ) = F^i \left( \lim_{t \to \infty} \by_t \right) = F^i ( \bx_{\star}) ,
\]
establishing that player $i$ is satisfied at $\bx_{\star}$, and thus that $\Sat(\bx_k) \subset \Sat(\bx_{\star})$. Then, by \eqref{subset:unsat-inside-sat}, we had $\UnSat(\bx_k) \subset \Sat(\bx_{\star})$, hence $\Sat(\bx_{\star}) = [n]$, and $\bx_{\star}$ is a Nash equilibrium accessible from $\bx_k$.  We put $T = k+1$ and $\bx_{T} = \bx_{\star}$, which completes the proof, since $(\bx_1, \dots, \bx_T)$ is a satisficing path terminating at a Nash equilibrium.  
\end{proof}



\subsection{Algorithmic insights from the proof of Theorem 1}


When coupled with a MARL algorithm that uses an exploratory satisficing strategy update, play will be driven along satisficing paths. \Cref{theorem:main} shows that for any starting strategy profile, some such path connects the strategy profile to an equilibrium, and so a sufficiently exploratory strategy update may drive play to equilibrium along a satisficing path. This offers important insights for the design of MARL algorithms. The first takeaway from \Cref{theorem:main} is that play can be driven to equilibrium by changing only the strategies of those players who are not best responding. In particular, this means that a satisfied agent does not need to continue updating its strategy after it becomes satisfied. As we will discuss in the next section, this property is helpful in distributed and decentralized multi-agent systems, where agents are able to assess whether they are satisfied but may not be able to assess whether the overall system is at equilibrium. 

A second, more subtle takeaway comes from the proof of \Cref{theorem:main} and relates to the unorthodox and counterintuitive exploration scheme used to drive play to equilibrium. In the proof, one sees that suboptimal---and perhaps even \emph{reward-deteriorating}---strategic updates were key to driving play to equilibrium along a satisficing path. As we outline below, this construction runs against the conventional approaches to designing MARL algorithms, and it can be used to avoid common pitfalls of MARL algorithms such as cyclical behavior. 

At a high level, many existing multi-agent learning algorithms update the strategy parameter in a \emph{reward-improving} direction at each step. A related approach, described earlier, increments the strategy parameter in a regret-minimizing direction, which has a similar effect. While such algorithms are sensible from the point of view of a single self-interested individual, they may fail to drive play to a Nash equilibrium when all players adopt similar algorithms \cite{mazumdar2020gradient, flokas2019poincare, mertikopoulos2018cycles}. To address this non-convergence issue, one recurring algorithmic modification involves manipulating step sizes, either with a mixture of fast agents and slow agents \cite{daskalakis2020independent} or with each individual varying its step sizes according to its performance \cite{bowling2002multiagent}. However, such approaches only come with provable convergence guarantees in select subclasses of games with exploitable structure. In instances where step size manipulation does not (or cannot) yield convergence, the analysis of \Cref{theorem:main} may offer an alternative route to algorithm modification. 


With these two takeaways in mind, we envision at least two design principles that will be useful for future MARL algorithms. First, strategic updating may incorporate some measure of randomness when a player is not satisfied. This principle has been previously used with some success, but comes with a drawback relating to complexity. A second principle, which we believe to be new, leverages the second takeaway above, involving counterintuitive path construction: players may alternate between reward-improving periods (during which strategy updates are done in a conventional way that improves the agent's reward) and suboptimal periods (during which reward-deteriorating and/or random strategy updates may be used). The timing of such periods or the extent of the randomness in strategic updates may be made to depend on whether cycles in the strategy iterates were detected. By incorporating suboptimal exploration in an adaptive manner, a MARL algorithm can break cycles as needed but rely on conventional algorithms the remainder of the time. 
